{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "526d8594-cc99-42de-9d3e-da27e558d318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import libraries\n",
    "import numpy as np\n",
    "import laspy\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import rerun as rr\n",
    "import open3d as o3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b721e18-d28a-44c2-9f1d-6c0876b29816",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ndvi(red, nir):\n",
    "    nir = np.array(nir, dtype=np.float64)\n",
    "    red = np.array(red, dtype=np.float64)\n",
    "    \n",
    "    return (nir - red) / (nir + red + 1e-8)  # Add small epsilon to avoid division by zero\n",
    "    # Cap the NDVI value between -1 and 1\n",
    "    #ndvi_capped = max(-1, min(1, ndvi))\n",
    "    #return ndvi_capped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "936658e2-dff8-4903-9b0e-406a58d618cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Files\n",
    "input_file = \"tud_sim/tudcampus_class1.laz\"\n",
    "output_file = \"tud_sim/tudcampus_sim_w_ndvi_new.laz\"\n",
    "#processed_las = process_laz_file(input_file, output_file)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2d507dae-bcf6-48dd-8d34-9a4291eb34a4",
   "metadata": {},
   "source": [
    "# Here should be the part where NIR maps can be loaded and overlayed over point cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92d90e6c-1dec-435c-bdb9-7f2b40f6b09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X', 'Y', 'Z', 'intensity', 'return_number', 'number_of_returns', 'synthetic', 'key_point', 'withheld', 'overlap', 'scanner_channel', 'scan_direction_flag', 'edge_of_flight_line', 'classification', 'user_data', 'scan_angle', 'point_source_id', 'gps_time', 'red', 'green', 'blue', 'nir', 'Amplitude', 'Reflectance', 'Deviation']\n"
     ]
    }
   ],
   "source": [
    "# Open LAS\n",
    "with laspy.open(input_file) as infile:\n",
    "    las = infile.read()\n",
    "\n",
    "    print(list(las.header.point_format.dimension_names))\n",
    "\n",
    "    red = las.red\n",
    "    nir = las.nir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c834ff78-4c24-495f-8b53-88feacac5b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate NDVI\n",
    "ndvi_calc = calculate_ndvi(red, nir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d7373852-0e60-4813-ad92-14661fb06df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X', 'Y', 'Z', 'intensity', 'return_number', 'number_of_returns', 'synthetic', 'key_point', 'withheld', 'overlap', 'scanner_channel', 'scan_direction_flag', 'edge_of_flight_line', 'classification', 'user_data', 'scan_angle', 'point_source_id', 'gps_time', 'red', 'green', 'blue', 'nir', 'Amplitude', 'Reflectance', 'Deviation', 'ndvi']\n"
     ]
    }
   ],
   "source": [
    "# Make the new point cloud\n",
    "out_las = las\n",
    "out_las.add_extra_dim(laspy.ExtraBytesParams(name=\"ndvi\", type=np.float32))\n",
    "out_las.ndvi = ndvi_calc\n",
    "\n",
    "print(list(out_las.header.point_format.dimension_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "39e5d997-984d-40c2-890d-93ea03a42da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the filtering of the points\n",
    "# Filter 1: Filter out points with NDVI value under 0.5\n",
    "ndvi_threshold = -1\n",
    "out_las = out_las[out_las.ndvi > ndvi_threshold]\n",
    "\n",
    "# Filter 2: Remove points with single return\n",
    "out_las = out_las[out_las.number_of_returns > 1]\n",
    "\n",
    "# Filter 3: Remove last return of all remaining points\n",
    "out_las = out_las[out_las.return_number != out_las.number_of_returns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fcd08bcb-9d01-4bd8-80bd-72ac859ddac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers using SOR\n",
    "def remove_outliers(las_data, nb_neighbors=20, std_ratio=2.0):\n",
    "    # Convert LAS data to Open3D point cloud\n",
    "    xyz = np.vstack((las_data.x, las_data.y, las_data.z)).transpose()\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(xyz)\n",
    "\n",
    "    # Perform statistical outlier removal\n",
    "    cl, ind = pcd.remove_statistical_outlier(nb_neighbors=nb_neighbors, std_ratio=std_ratio)\n",
    "    \n",
    "    # Filter the original LAS data\n",
    "    filtered_las = las_data[ind]\n",
    "    \n",
    "    return filtered_las\n",
    "\n",
    "# After your previous filtering steps:\n",
    "out_las = remove_outliers(out_las, 20, 2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bae6156e-977e-4352-8438-ad355045c418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualization ready. Run 'rerun' in terminal to view.\n"
     ]
    }
   ],
   "source": [
    "def visualize_point_cloud_with_rerun(las_data, sample_size=None):\n",
    "    # Initialize rerun\n",
    "    rr.init(\"LAS Point Cloud Viewer - NDVI, NIR, Red\")\n",
    "\n",
    "    # Check if red and nir bands exist\n",
    "    if not (hasattr(las_data, 'red') and hasattr(las_data, 'nir')):\n",
    "        raise ValueError(\"The LAS file does not contain 'red' and 'nir' bands required for NDVI calculation.\")\n",
    "\n",
    "    # Calculate NDVI\n",
    "    ndvi = calculate_ndvi(las_data.red, las_data.nir)\n",
    "\n",
    "    # Sample the data if sample_size is provided\n",
    "    if sample_size is not None and sample_size < len(las_data.points):\n",
    "        indices = np.random.choice(len(las_data.points), sample_size, replace=False)\n",
    "        points = np.column_stack((las_data.x[indices], las_data.y[indices], las_data.z[indices]))\n",
    "        ndvi_values = ndvi[indices]\n",
    "        nir_values = las_data.nir[indices]\n",
    "        red_values = las_data.red[indices]\n",
    "    else:\n",
    "        points = np.column_stack((las_data.x, las_data.y, las_data.z))\n",
    "        ndvi_values = ndvi\n",
    "        nir_values = las_data.nir\n",
    "        red_values = las_data.red\n",
    "\n",
    "    # Normalize NIR and Red values to 0-1 range\n",
    "    nir_normalized = (nir_values - np.min(nir_values)) / (np.max(nir_values) - np.min(nir_values))\n",
    "    red_normalized = (red_values - np.min(red_values)) / (np.max(red_values) - np.min(red_values))\n",
    "\n",
    "    # Create color array: Red channel for Red values, Green for NDVI, Blue for NIR\n",
    "    colors = np.column_stack((\n",
    "        red_normalized,\n",
    "        (ndvi_values + 1) / 2,  # NDVI is already in [-1, 1] range, normalize to [0, 1]\n",
    "        nir_normalized\n",
    "    ))\n",
    "\n",
    "    # Log the point cloud to rerun\n",
    "    rr.log(\"point_cloud\", \n",
    "           rr.Points3D(\n",
    "               positions=points,\n",
    "               colors=colors,\n",
    "               #radii=0.5,  # Adjust point size as needed\n",
    "               labels=[f\"NDVI: {ndvi:.3f}, NIR: {nir:.3f}, Red: {red:.3f}\" \n",
    "                       for ndvi, nir, red in zip(ndvi_values, nir_values, red_values)]\n",
    "           ))\n",
    "\n",
    "    # Log some text to provide context\n",
    "    rr.log(\"info\", rr.TextLog(\"Point cloud: Red channel = Red band, Green channel = NDVI, Blue channel = NIR band. Hover for values.\"))\n",
    "\n",
    "    print(f\"Visualization ready. Run 'rerun' in terminal to view.\")\n",
    "\n",
    "visualize_point_cloud_with_rerun(out_las, sample_size=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e2b6b0f-9760-42c1-9bb1-393956a39074",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d9295a0e42d46bfafe04bff0adff316",
       "version_major": 2,
       "version_minor": 1
      },
      "text/plain": [
       "Viewer()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rr.notebook_show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "69f1be0f-1484-4451-8b23-f2cb1ac0b770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the point cloud to file\n",
    "out_las.write(output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3491da11-bc2c-483e-b8ad-41ff2c6ae6bc",
   "metadata": {},
   "source": [
    "# Continue with Open3D to calculate and output alpha shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6d1914a4-f93d-480d-8afa-fb58cd70de9d",
   "metadata": {},
   "source": [
    "# Load points\n",
    "points = np.vstack((out_las.x, out_las.y, out_las.z)).transpose()\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(points)\n",
    "\n",
    "# Optional: Downsample the point cloud if it's too large\n",
    "# voxel_size = 0.05  # Adjust this value as needed\n",
    "# pcd = pcd.voxel_down_sample(voxel_size)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "eb17c7ed-e2b0-4cd8-ac7f-e6466a029c7e",
   "metadata": {},
   "source": [
    "# Cluster the point cloud using DBSCAN\n",
    "eps = 1.5  # Adjust this value based on your data\n",
    "min_points = 10  # Minimum number of points to form a cluster\n",
    "labels = np.array(pcd.cluster_dbscan(eps=eps, min_points=min_points))\n",
    "\n",
    "# Get the number of clusters (excluding noise, which is labeled as -1)\n",
    "max_label = labels.max()\n",
    "print(f\"Number of clusters: {max_label + 1}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bdbca37b-2948-4a51-be88-6e72bcb54b44",
   "metadata": {},
   "source": [
    "# DEBUG: Visualize a specific cluster (e.g., cluster 0)\n",
    "cluster_points = pcd.select_by_index(np.where(labels == 500)[0])\n",
    "o3d.visualization.draw_geometries([cluster_points])\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "815646da-54a1-48bf-90a8-83556623f4d8",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Function to create mesh from a cluster\n",
    "def create_mesh_from_cluster(cluster_pcd, alpha):\n",
    "    try:\n",
    "        if len(cluster_pcd.points) < 4:\n",
    "            return None  # Not enough points to create a tetrahedron\n",
    "        \n",
    "        mesh = o3d.geometry.TriangleMesh.create_from_point_cloud_alpha_shape(cluster_pcd, alpha)\n",
    "        \n",
    "        if mesh.is_empty():\n",
    "            return None  # Mesh creation failed\n",
    "        \n",
    "        mesh.compute_vertex_normals()\n",
    "        mesh.remove_degenerate_triangles()\n",
    "        mesh.remove_duplicated_triangles()\n",
    "        mesh.remove_duplicated_vertices()\n",
    "        mesh.remove_non_manifold_edges()\n",
    "        return mesh\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating mesh: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def create_mesh_from_cluster_poisson(cluster_pcd):\n",
    "    cluster_pcd.estimate_normals()\n",
    "    mesh, densities = o3d.geometry.TriangleMesh.create_from_point_cloud_poisson(cluster_pcd, depth=8)\n",
    "    return mesh\n",
    "\n",
    "# Initialize an empty mesh to store the combined result\n",
    "combined_mesh = o3d.geometry.TriangleMesh()\n",
    "\n",
    "mesh_list = []\n",
    "\n",
    "# Process each cluster\n",
    "for i in range(max_label + 1):\n",
    "    # Get points belonging to the current cluster\n",
    "    cluster_points = pcd.select_by_index(np.where(labels == i)[0])\n",
    "    \n",
    "    if len(cluster_points.points) < 3:\n",
    "        continue  # Skip clusters with too few points\n",
    "    \n",
    "    # Create mesh for this cluster\n",
    "    alpha = 0.5  # You may need to adjust this value\n",
    "    #cluster_mesh = create_mesh_from_cluster(cluster_points, alpha)\n",
    "    cluster_mesh = create_mesh_from_cluster_poisson(cluster_points)\n",
    "    \n",
    "    if cluster_mesh is not None:\n",
    "        # Add to the mesh list\n",
    "        mesh_list.append(cluster_mesh)\n",
    "    else:\n",
    "        print(f\"Skipping cluster {i} due to mesh creation failure\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1ef93a9c-d5a9-41f6-b8de-e755e580fd9e",
   "metadata": {},
   "source": [
    "# Optional: Simplify the combined mesh if it's too complex\n",
    "# combined_mesh = combined_mesh.simplify_quadric_decimation(100000)\n",
    "\n",
    "# Save the combined mesh as OBJ\n",
    "o3d.io.write_triangle_mesh(\"output_combined_mesh.obj\", combined_mesh)\n",
    "\n",
    "print(\"Mesh creation complete. Saved as 'output_combined_mesh.obj'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d5948ee2-913d-47d9-a98d-b92dcf4da51e",
   "metadata": {},
   "source": [
    "# Optional: Visualize the combined mesh\n",
    "o3d.visualization.draw_geometries([combined_mesh])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
